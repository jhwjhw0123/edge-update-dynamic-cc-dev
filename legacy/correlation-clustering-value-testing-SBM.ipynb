{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "written-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import tqdm\n",
    "from collections import defaultdict\n",
    "from scipy.spatial import distance_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-board",
   "metadata": {},
   "source": [
    "## Implement the simulator of graph stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-adoption",
   "metadata": {},
   "source": [
    "#### The stochastic block model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "leading-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBMGraphStream():\n",
    "    '''\n",
    "    The class of Graph Stream from the stochastic block model\n",
    "    ----- Parameters -----\n",
    "    # n_vertex: the number of vertices in the graph\n",
    "    # p_intra: the probability for + edge (u,v) for the same cluster\n",
    "    # p_inter: the probability for + edge (u,v) for different clusters\n",
    "    # k_cluster: number of clusters in the clustering\n",
    "    ----- Methods ----\n",
    "    # read_next_edge(): read the next edge and move the index +1\n",
    "    ----- Representation ----\n",
    "    The graph is representation with an indexed array of vertices and a dictionary with (u_i, u_j): labels\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_vertex, p_intra=0.8, p_inter=0.2, k_cluster=7):\n",
    "        '''\n",
    "        :param n_vertex: the the number of vertices in the graph\n",
    "        '''\n",
    "        self.n_vertex = n_vertex\n",
    "        self.p_intra = p_intra\n",
    "        self.p_inter = p_inter\n",
    "        self.k_cluster = k_cluster\n",
    "        \n",
    "        # initialize the vertex set and the cluster labels\n",
    "        self.vertex_set = np.array([self.n_vertex])\n",
    "        num_v_per_cluster = n_vertex//self.k_cluster\n",
    "        n_residual = n_vertex % num_v_per_cluster\n",
    "        cluster_labels_list = []\n",
    "        for i_cluster in range(k_cluster):\n",
    "            cluster_labels_list.append(i_cluster*np.ones([num_v_per_cluster]))\n",
    "        if n_residual!=0:\n",
    "            cluster_labels_list.append((k_cluster-1)*np.ones([n_residual]))\n",
    "        # collect them as a 1-d array\n",
    "        self.cluster_labels = np.reshape(np.hstack(cluster_labels_list).astype(int), [-1])\n",
    "        # initialize the edges -- using +1 and -1 to represent the edge labels\n",
    "        # also compute the cost\n",
    "        self.cc_cost = 0\n",
    "        self.edge_dict = {}\n",
    "        for u_i in tqdm.tqdm(range(self.n_vertex)):\n",
    "            for u_j in np.arange(u_i+1, self.n_vertex):\n",
    "                if self.cluster_labels[u_i] == self.cluster_labels[u_j]:\n",
    "                    if np.random.rand() <= p_intra:\n",
    "                        self.edge_dict[(u_i,u_j)] = 1\n",
    "                    else:\n",
    "                        self.edge_dict[(u_i,u_j)] = -1\n",
    "                        self.cc_cost = self.cc_cost + 1\n",
    "                else:\n",
    "                    if np.random.rand() <= p_inter:\n",
    "                        self.edge_dict[(u_i,u_j)] = 1\n",
    "                        self.cc_cost = self.cc_cost + 1\n",
    "                    else:\n",
    "                        self.edge_dict[(u_i,u_j)] = -1\n",
    "        # randomize the order of edge arrival\n",
    "        self.edge_names = list(self.edge_dict.keys())\n",
    "        random.shuffle(self.edge_names)\n",
    "        self.num_edges = len(self.edge_names)\n",
    "        # maintain a pointer of the number of edges\n",
    "        self.current_stream_ind = 0\n",
    "        \n",
    "    def read_next_edge(self):\n",
    "        \n",
    "        this_edge_name = self.edge_names[self.current_stream_ind]\n",
    "        this_edge_label = self.edge_dict[this_edge_name]\n",
    "        self.current_stream_ind = self.current_stream_ind + 1\n",
    "        if self.current_stream_ind>=self.num_edges-1:\n",
    "            return None, None\n",
    "        \n",
    "        return this_edge_name, this_edge_label\n",
    "    \n",
    "    def reset_index(self):\n",
    "        '''\n",
    "        reset the pointer\n",
    "        '''\n",
    "        self.current_stream_ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "integral-atlas",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2117.07it/s]\n"
     ]
    }
   ],
   "source": [
    "sbm_graph_stream = SBMGraphStream(n_vertex=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dressed-surprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499500\n",
      "The first edge is  (329, 648) and the label is  1\n"
     ]
    }
   ],
   "source": [
    "print(sbm_graph_stream.num_edges)\n",
    "first_edge, first_edge_label = sbm_graph_stream.read_next_edge()\n",
    "print('The first edge is ', first_edge, 'and the label is ', first_edge_label)\n",
    "sbm_graph_stream.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-timeline",
   "metadata": {},
   "source": [
    "#### The Erdos-Renyi graph class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adopted-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErdosRenyiGraphStream():\n",
    "    '''\n",
    "    The class of Graph Stream from the Erdos-Renyi graph\n",
    "    ----- Parameters -----\n",
    "    # n_vertex: the number of vertices in the graph\n",
    "    # p_edge: the probability for an edge to be sampled\n",
    "    ----- Methods ----\n",
    "    # read_next_edge(): read the next edge and move the index +1\n",
    "    ----- Representation ----\n",
    "    The graph is representation with an indexed array of vertices and a dictionary with (u_i, u_j): labels\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_vertex, p_edge=0.5):\n",
    "        '''\n",
    "        :param n_vertex: the the number of vertices in the graph\n",
    "        '''\n",
    "        self.n_vertex = n_vertex\n",
    "        self.p_edge = p_edge\n",
    "        \n",
    "        # initialize the vertex set and the cluster labels\n",
    "        self.vertex_set = np.array([self.n_vertex])\n",
    "        # maintain the cost as (basically) the number of (+) edges\n",
    "        self.cc_cost = 0\n",
    "        self.edge_dict = {}\n",
    "        for u_i in tqdm.tqdm(range(self.n_vertex)):\n",
    "            for u_j in np.arange(u_i+1, self.n_vertex):\n",
    "                if np.random.rand() <= self.p_edge:\n",
    "                    self.edge_dict[(u_i,u_j)] = 1\n",
    "                    self.cc_cost = self.cc_cost + 1\n",
    "                else:\n",
    "                    self.edge_dict[(u_i,u_j)] = -1\n",
    "        # randomize the order of edge arrival\n",
    "        self.edge_names = list(self.edge_dict.keys())\n",
    "        random.shuffle(self.edge_names)\n",
    "        self.num_edges = len(self.edge_names)\n",
    "        # maintain a pointer of the number of edges\n",
    "        self.current_stream_ind = 0\n",
    "        \n",
    "    def read_next_edge(self):\n",
    "        \n",
    "        this_edge_name = self.edge_names[self.current_stream_ind]\n",
    "        this_edge_label = self.edge_dict[this_edge_name]\n",
    "        self.current_stream_ind = self.current_stream_ind + 1\n",
    "        if self.current_stream_ind>=self.num_edges-1:\n",
    "            return None, None\n",
    "        \n",
    "        return this_edge_name, this_edge_label\n",
    "    \n",
    "    def reset_index(self):\n",
    "        '''\n",
    "        reset the pointer\n",
    "        '''\n",
    "        self.current_stream_ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "synthetic-aside",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2028.17it/s]\n"
     ]
    }
   ],
   "source": [
    "random_graph_stream = ErdosRenyiGraphStream(n_vertex=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prostate-democrat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499500\n",
      "The first edge is  (810, 813) and the label is  1\n"
     ]
    }
   ],
   "source": [
    "print(random_graph_stream.num_edges)\n",
    "first_edge, first_edge_label = random_graph_stream.read_next_edge()\n",
    "print('The first edge is ', first_edge, 'and the label is ', first_edge_label)\n",
    "random_graph_stream.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stuffed-border",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal SBM cost is  100041\n",
      "The optimal random graph cost is  249479\n"
     ]
    }
   ],
   "source": [
    "print('The optimal SBM cost is ', sbm_graph_stream.cc_cost)\n",
    "print('The optimal random graph cost is ', random_graph_stream.cc_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-jumping",
   "metadata": {},
   "source": [
    "## Implementation of the SDD-based algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wanted-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseEdgeTool:\n",
    "    '''\n",
    "    A class that tests if a given edge is sparse (on the `+' edges)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, edge_name, n_vertex, eps=0.2):\n",
    "        '''\n",
    "        :param n_vertex: the the number of vertices in the graph\n",
    "        '''\n",
    "        self.edge_name = edge_name\n",
    "        self.n_vertex = n_vertex\n",
    "        self.eps = eps\n",
    "        # sample a set of log n vertices\n",
    "        self.n_sample_vertex = max((int)(5*np.log(self.n_vertex)), 20)\n",
    "        self.sample_vertex_set = np.random.choice(self.n_vertex, self.n_sample_vertex, replace=False)\n",
    "        self.endpoint_one = edge_name[0]\n",
    "        self.endpoint_two = edge_name[1]\n",
    "        self.neighbors_one = []\n",
    "        self.neighbors_two = []\n",
    "        self.degree_one = 0\n",
    "        self.degree_two = 0\n",
    "        self.plabel = False\n",
    "        \n",
    "    def read_edge_and_process(self, e, label):\n",
    "        if label == 1:\n",
    "            # count the degree\n",
    "            if (e[0]==self.endpoint_one) or (e[1]==self.endpoint_one):\n",
    "                self.degree_one += 1\n",
    "            if (e[0]==self.endpoint_two) or (e[1]==self.endpoint_two):\n",
    "                self.degree_two += 1\n",
    "            # determine the sampled neightbors\n",
    "            if (e[0] in self.sample_vertex_set) or (e[1] in self.sample_vertex_set):\n",
    "                # process the edge if connected to the first endpoint\n",
    "                if (e[0]==self.endpoint_one) or (e[1]==self.endpoint_one):\n",
    "                    arrive_edge_list = list(e)\n",
    "                    arrive_edge_list.remove(self.endpoint_one)\n",
    "                    self.neighbors_one.append(arrive_edge_list[0])\n",
    "                # process the edge if connected to the second endpoint\n",
    "                if (e[0]==self.endpoint_two) or (e[1]==self.endpoint_two):\n",
    "                    arrive_edge_list = list(e)\n",
    "                    arrive_edge_list.remove(self.endpoint_two)\n",
    "                    self.neighbors_two.append(arrive_edge_list[0])\n",
    "            elif (e[0] in self.edge_name) and (e[1] in self.edge_name):\n",
    "                self.plabel = True\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "                \n",
    "    def determine_sparse(self):\n",
    "        dif1 = np.setdiff1d(self.neighbors_one, self.neighbors_two)\n",
    "        dif2 = np.setdiff1d(self.neighbors_two, self.neighbors_one)\n",
    "        total_diff = np.concatenate([dif1, dif2])\n",
    "        total_elements = list(set(self.neighbors_one + self.neighbors_two))\n",
    "        \n",
    "        if (len(total_diff)>=self.eps*len(total_elements)) and self.plabel:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "metallic-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseEdgeTool:\n",
    "    '''\n",
    "    A class that tests if a given edge is dense (on the `--' edges)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, edge_name, n_vertex, eps=0.2):\n",
    "        '''\n",
    "        :param n_vertex: the the number of vertices in the graph\n",
    "        '''\n",
    "        self.edge_name = edge_name\n",
    "        self.n_vertex = n_vertex\n",
    "        self.eps = eps\n",
    "        # sample a set of log n vertices\n",
    "        self.n_sample_vertex = max((int)(5*np.log(self.n_vertex)), 20)\n",
    "        self.sample_vertex_set = np.random.choice(self.n_vertex, self.n_sample_vertex, replace=False)\n",
    "        self.endpoint_one = edge_name[0]\n",
    "        self.endpoint_two = edge_name[1]\n",
    "        self.degree_one = 0\n",
    "        self.degree_two = 0\n",
    "        self.neighbors_one = []\n",
    "        self.neighbors_two = []\n",
    "        self.nlabel = False\n",
    "        \n",
    "    def read_edge_and_process(self, e, label):\n",
    "        if label == 1:\n",
    "            # count the degree\n",
    "            if (e[0]==self.endpoint_one) or (e[1]==self.endpoint_one):\n",
    "                self.degree_one += 1\n",
    "            if (e[0]==self.endpoint_two) or (e[1]==self.endpoint_two):\n",
    "                self.degree_two += 1\n",
    "            # determine the sampled neighbors\n",
    "            if (e[0] in self.sample_vertex_set) or (e[1] in self.sample_vertex_set):\n",
    "                # process the edge if connected to the first endpoint\n",
    "                if (e[0]==self.endpoint_one) or (e[1]==self.endpoint_one):\n",
    "                    arrive_edge_list = list(e)\n",
    "                    arrive_edge_list.remove(self.endpoint_one)\n",
    "                    self.neighbors_one.append(arrive_edge_list[0])\n",
    "                # process the edge if connected to the second endpoint\n",
    "                if (e[0]==self.endpoint_two) or (e[1]==self.endpoint_two):\n",
    "                    arrive_edge_list = list(e)\n",
    "                    arrive_edge_list.remove(self.endpoint_two)\n",
    "                    self.neighbors_two.append(arrive_edge_list[0])\n",
    "        elif (e[0] in self.edge_name) and (e[1] in self.edge_name):\n",
    "            self.nlabel = True\n",
    "        \n",
    "    def determine_dense(self):\n",
    "        dif1 = np.setdiff1d(self.neighbors_one, self.neighbors_two)\n",
    "        dif2 = np.setdiff1d(self.neighbors_two, self.neighbors_one)\n",
    "        total_diff = np.concatenate([dif1, dif2])\n",
    "        total_elements = list(set(self.neighbors_one + self.neighbors_two))\n",
    "        \n",
    "        if (len(total_diff)<self.eps*len(total_elements)) and self.nlabel:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abandoned-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main SDD-based streaming value tester\n",
    "def SDD_cost_eval(graph_stream, eps=0.2, delta=0.1, add_error=False, rescale_spr=False):\n",
    "    # parameters\n",
    "    n_vertex = graph_stream.n_vertex\n",
    "    n_edges = sbm_graph_stream.num_edges\n",
    "    n_sparse_pairs = max((int)(5*np.log(n_vertex)), 20)\n",
    "    n_dense_vertex = max((int)(5*np.log(n_vertex)), 15)\n",
    "    n_dense_vertex_neighbors =  max((int)(5*np.log(n_vertex)), 15)\n",
    "    total_edges_store = 0\n",
    "    \n",
    "    # initialize all the tools for process\n",
    "    print('Pre-processing...')\n",
    "    sparse_edge_tools_list = [] # this will be a list of tools\n",
    "    dense_vertex_tools_list = [] # this will be a list of lists of tools\n",
    "    for c_tool in range(n_sparse_pairs):\n",
    "        this_edge = tuple(np.random.choice(n_vertex, 2, replace=False))\n",
    "        sparse_edge_tools_list.append(SparseEdgeTool(this_edge, n_vertex, eps=eps))\n",
    "    for c_vertex in range(n_dense_vertex):\n",
    "        # main n_dense_vertex_neighbors tools for each of the vertex\n",
    "        base_vertex = np.random.choice(n_vertex, 1)[0]\n",
    "        this_vertex_dense_tool_list = []\n",
    "        for c_neighbor in range(n_dense_vertex_neighbors):\n",
    "            # repeat sample -- could run to infinite lool but very very unlikely\n",
    "            while(True):\n",
    "                this_neighbor_vertex = np.random.choice(n_vertex, 1)[0]\n",
    "                if this_neighbor_vertex!= base_vertex:\n",
    "                    break\n",
    "            # creat a tool and append\n",
    "            this_vertex_dense_tool_list.append(DenseEdgeTool((base_vertex, this_neighbor_vertex), n_vertex, eps=eps))\n",
    "        dense_vertex_tools_list.append(this_vertex_dense_tool_list)\n",
    "    \n",
    "    print('Processing the stream...')\n",
    "    # read the stream and process on-the-fly\n",
    "    for i in tqdm.tqdm(range(n_edges)):\n",
    "        this_edge, this_edge_label = sbm_graph_stream.read_next_edge()\n",
    "        if this_edge is None:\n",
    "            break\n",
    "        for c_tool in range(n_sparse_pairs):\n",
    "            sparse_edge_tools_list[c_tool].read_edge_and_process(this_edge, this_edge_label)\n",
    "        for c_vertex in range(n_dense_vertex):\n",
    "            for c_neighbor in range(n_dense_vertex_neighbors):\n",
    "                dense_vertex_tools_list[c_vertex][c_neighbor].read_edge_and_process(this_edge, this_edge_label)\n",
    "                \n",
    "    # post-processing\n",
    "    print('Post-processing...')\n",
    "    # estimation of E-spr\n",
    "    E_spr_est = 0\n",
    "    valid_E_spr = 0\n",
    "    for c_tool in range(n_sparse_pairs): \n",
    "        E_spr_est += sparse_edge_tools_list[c_tool].determine_sparse()\n",
    "        total_edges_store = total_edges_store + len(sparse_edge_tools_list[c_tool].\n",
    "                                                    neighbors_one) + len(sparse_edge_tools_list[c_tool].neighbors_two)\n",
    "        if (sparse_edge_tools_list[c_tool].degree_one>=\n",
    "            delta*n_vertex) and (sparse_edge_tools_list[c_tool].degree_two>=delta*n_vertex):\n",
    "            valid_E_spr += 1\n",
    "    E_spr_est_final = E_spr_est*(n_edges/valid_E_spr)\n",
    "    # estimation of E-dens\n",
    "    E_den_est = 0\n",
    "    for c_vertex in range(n_dense_vertex):\n",
    "        this_base_vertex_degree = dense_vertex_tools_list[c_vertex][0].degree_one\n",
    "        for c_neighbor in range(n_dense_vertex_neighbors):\n",
    "            total_edges_store = total_edges_store + len(\n",
    "                dense_vertex_tools_list[c_vertex][c_neighbor].neighbors_one) + len(\n",
    "                dense_vertex_tools_list[c_vertex][c_neighbor].neighbors_two)\n",
    "        if this_base_vertex_degree<delta*n_vertex:\n",
    "            continue\n",
    "        this_vertex_est = 0\n",
    "        for c_neighbor in range(n_dense_vertex_neighbors):\n",
    "            this_vertex_est += dense_vertex_tools_list[c_vertex][c_neighbor].determine_dense()\n",
    "        Y_v = min(this_base_vertex_degree, this_vertex_est*(n_vertex/n_dense_vertex_neighbors))\n",
    "        E_den_est += Y_v\n",
    "    # putting everything together\n",
    "    if add_error:\n",
    "        E_spr_est_final = E_spr_est_final + delta*n_edges\n",
    "        E_den_est = E_den_est + delta*n_edges\n",
    "    if rescale_spr:\n",
    "        E_spr_est_final = E_spr_est_final/eps\n",
    "    \n",
    "    return E_den_est + E_spr_est_final, total_edges_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "forward-helmet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 24/499500 [00:00<34:42, 239.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the stream...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 499498/499500 [22:41<00:00, 366.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing...\n"
     ]
    }
   ],
   "source": [
    "sbm_graph_stream.reset_index()\n",
    "SDD_cost_est, SDD_total_stored_edge = SDD_cost_eval(sbm_graph_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ideal-sodium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected SBM cost is  100041\n",
      "The estimated correlation clustering cost is  44073.529411764706\n"
     ]
    }
   ],
   "source": [
    "print('The expected SBM cost is ', sbm_graph_stream.cc_cost)\n",
    "print('The estimated correlation clustering cost is ', SDD_cost_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cathedral-portfolio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of edges in the graphs is  499500\n",
      "The number of edges stored by the algorithm is  44068\n"
     ]
    }
   ],
   "source": [
    "print('The number of edges in the graphs is ', sbm_graph_stream.num_edges)\n",
    "print('The number of edges stored by the algorithm is ', SDD_total_stored_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-violence",
   "metadata": {},
   "source": [
    "## Implementation of the Pivot-based algorithm\n",
    "Barrier: it seems it's hard for us to actually go through 2^(1/delta) permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "gothic-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_1 = (1,20)\n",
    "tuple_2 = (20, 19, 98, 71)\n",
    "aa = list(set(tuple_1).intersection(set(tuple_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fatal-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredAwareNE:\n",
    "    '''\n",
    "    This is the class that implements the predecessor-aware non-edge sketh\n",
    "    '''\n",
    "    def __init__(self, vertex_name, n_vertex, pred_set, eps=0.2, delta=0.1):\n",
    "        '''\n",
    "        :param n_vertex: the the number of vertices in the graph\n",
    "        '''\n",
    "        if vertex_name in pred_set:\n",
    "            raise ValueError('The tested vertex cannot be inside the set!')\n",
    "        self.n_vertex = n_vertex\n",
    "        self.n_edges = (int)(n_vertex*(n_vertex-1)/2)\n",
    "        self.vertex_name = vertex_name\n",
    "        self.vertex_degree = 0\n",
    "        self.eps = eps\n",
    "        self.delta = delta\n",
    "        # sample a set of log n vertices\n",
    "        self.n_sample_edges = max((int)(5*np.log(self.n_vertex)), 20)\n",
    "        self.sample_edge_set = []\n",
    "        self.first_endpoint_set = []\n",
    "        self.second_endpoint_set = []\n",
    "        # keep track of the endpoints' connection to u and S\n",
    "        self.first_endpoint_to_u = self.n_sample_edges*[False]\n",
    "        self.first_endpoint_to_S = self.n_sample_edges*[False]\n",
    "        self.second_endpoint_to_u = self.n_sample_edges*[False]\n",
    "        self.second_endpoint_to_S = self.n_sample_edges*[False]\n",
    "        for i_edge in range(self.n_sample_edges):\n",
    "            # to avoid sample the same vertex, try repetitive sampling\n",
    "            while(True):\n",
    "                first_vertex = np.random.choice(self.n_vertex, 1)[0]\n",
    "                second_vertex = np.random.choice(self.n_vertex, 1)[0]\n",
    "                if first_vertex!=second_vertex:\n",
    "                    break\n",
    "            self.sample_edge_set.append((first_vertex, second_vertex))\n",
    "            self.first_endpoint_set.append(first_vertex)\n",
    "            self.second_endpoint_set.append(second_vertex)\n",
    "            if first_vertex == self.vertex_name:\n",
    "                self.first_endpoint_to_u[i_edge] = True\n",
    "            if second_vertex == self.vertex_name:\n",
    "                self.second_endpoint_to_u[i_edge] = True\n",
    "            if first_vertex in pred_set:\n",
    "                self.first_endpoint_to_S[i_edge] = True\n",
    "            if second_vertex in pred_set:\n",
    "                self.second_endpoint_to_S[i_edge] = True\n",
    "        # edge labels\n",
    "        self.edge_label = self.n_sample_edges*[0]\n",
    "        self.pred_set = pred_set\n",
    "        \n",
    "    def read_edge_and_process(self, e, label):\n",
    "        for i_edge in range(self.n_sample_edges):\n",
    "            # if edge is some (x,y), update the label\n",
    "            this_edge_name = self.sample_edge_set[i_edge]\n",
    "            if this_edge_name==e or this_edge_name==(e[1],e[0]):\n",
    "                self.edge_label[i_edge] = label\n",
    "            # if edge connects x (or y) to u, mark it\n",
    "            if (self.first_endpoint_set[i_edge] in e) and (self.vertex_name in e) and (label == 1):\n",
    "                self.first_endpoint_to_u[i_edge] = True\n",
    "            if (self.second_endpoint_set[i_edge] in e) and (self.vertex_name in e) and (label == 1):\n",
    "                self.second_endpoint_to_u[i_edge] = True\n",
    "            # if there is intersection with S, mark it\n",
    "            if (self.first_endpoint_set[i_edge] in e) and list(set(e).\n",
    "                                                               intersection(set(self.pred_set))) and (label == 1):\n",
    "                self.first_endpoint_to_S[i_edge] = True\n",
    "            if (self.second_endpoint_set[i_edge] in e) and list(set(e).intersection(set(self.pred_set))) and (label == 1):\n",
    "                self.second_endpoint_to_S[i_edge] = True\n",
    "        # don't forget to count degree :D\n",
    "        if self.vertex_name in e and label==1:\n",
    "            self.vertex_degree += 1\n",
    "                \n",
    "    def determine_cost(self):\n",
    "        inside_non_edge_cost = 0\n",
    "        if self.vertex_degree<=self.delta*self.n_vertex:\n",
    "            return self.delta*self.n_vertex\n",
    "        else:\n",
    "            for i_edge in range(self.n_sample_edges):\n",
    "                if (self.first_endpoint_to_u[i_edge]\n",
    "                   ) and (self.second_endpoint_to_u[i_edge]\n",
    "                         ) and (not self.first_endpoint_to_S[i_edge]\n",
    "                               ) and (not self.second_endpoint_to_S[i_edge]\n",
    "                                     ) and (self.edge_label[i_edge]==-1):\n",
    "                    inside_non_edge_cost +=1\n",
    "            \n",
    "            return inside_non_edge_cost*self.n_edges/self.n_sample_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "divided-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredAwareE:\n",
    "    '''\n",
    "    This is the class that implements the predecessor-aware non-edge sketh\n",
    "    '''\n",
    "    def __init__(self, vertex_name, n_vertex, pred_set, eps=0.2, delta=0.1):\n",
    "        '''\n",
    "        :param n_vertex: the the number of vertices in the graph\n",
    "        '''\n",
    "        if vertex_name in pred_set:\n",
    "            raise ValueError('The tested vertex cannot be inside the set!')\n",
    "        self.n_vertex = n_vertex\n",
    "        self.n_edges = (int)(n_vertex*(n_vertex-1)/2)\n",
    "        self.vertex_name = vertex_name\n",
    "        self.vertex_degree = 0\n",
    "        self.eps = eps\n",
    "        self.delta = delta\n",
    "        # sample a set of log n vertices\n",
    "        self.n_sample_edges = max((int)(5*np.log(self.n_vertex)), 20)\n",
    "        self.sample_edge_set = []\n",
    "        self.first_endpoint_set = []\n",
    "        self.second_endpoint_set = []\n",
    "        # keep track of the endpoints' connection to u and S\n",
    "        self.first_endpoint_to_u = self.n_sample_edges*[False]\n",
    "        self.first_endpoint_to_S = self.n_sample_edges*[False]\n",
    "        self.second_endpoint_to_u = self.n_sample_edges*[False]\n",
    "        self.second_endpoint_to_S = self.n_sample_edges*[False]\n",
    "        for i_edge in range(self.n_sample_edges):\n",
    "            # to avoid sample the same vertex, try repetitive sampling\n",
    "            while(True):\n",
    "                first_vertex = np.random.choice(self.n_vertex, 1)[0]\n",
    "                second_vertex = np.random.choice(self.n_vertex, 1)[0]\n",
    "                if first_vertex!=second_vertex:\n",
    "                    break\n",
    "            self.sample_edge_set.append((first_vertex, second_vertex))\n",
    "            self.first_endpoint_set.append(first_vertex)\n",
    "            self.second_endpoint_set.append(second_vertex)\n",
    "            if first_vertex == self.vertex_name:\n",
    "                self.first_endpoint_to_u[i_edge] = True\n",
    "            if second_vertex == self.vertex_name:\n",
    "                self.second_endpoint_to_u[i_edge] = True\n",
    "            if first_vertex in pred_set:\n",
    "                self.first_endpoint_to_S[i_edge] = True\n",
    "            if second_vertex in pred_set:\n",
    "                self.second_endpoint_to_S[i_edge] = True\n",
    "        # edge labels\n",
    "        self.edge_label = self.n_sample_edges*[0]\n",
    "        self.pred_set = pred_set\n",
    "        \n",
    "    def read_edge_and_process(self, e, label):\n",
    "        for i_edge in range(self.n_sample_edges):\n",
    "            # if edge is some (x,y), update the label\n",
    "            this_edge_name = self.sample_edge_set[i_edge]\n",
    "            if this_edge_name==e or this_edge_name==(e[1],e[0]):\n",
    "                self.edge_label[i_edge] = label\n",
    "            # if edge connects x (or y) to u, mark it\n",
    "            if (self.first_endpoint_set[i_edge] in e) and (self.vertex_name in e) and (label == 1):\n",
    "                self.first_endpoint_to_u[i_edge] = True\n",
    "            if (self.second_endpoint_set[i_edge] in e) and (self.vertex_name in e) and (label == 1):\n",
    "                self.second_endpoint_to_u[i_edge] = True\n",
    "            # if there is intersection with S, mark it\n",
    "            if (self.first_endpoint_set[i_edge] in e) and list(set(e).\n",
    "                                                               intersection(set(self.pred_set))) and (label == 1):\n",
    "                self.first_endpoint_to_S[i_edge] = True\n",
    "            if (self.second_endpoint_set[i_edge] in e) and list(set(e).intersection(set(self.pred_set))) and (label == 1):\n",
    "                self.second_endpoint_to_S[i_edge] = True\n",
    "        # don't forget to count degree :D\n",
    "        if self.vertex_name in e and label==1:\n",
    "            self.vertex_degree += 1\n",
    "                \n",
    "    def determine_cost(self):\n",
    "        outside_edge_cost = 0\n",
    "        if self.vertex_degree<=self.delta*self.n_vertex:\n",
    "            return self.delta*self.n_vertex\n",
    "        else:\n",
    "            for i_edge in range(self.n_sample_edges):\n",
    "                if ((self.first_endpoint_to_u[i_edge] and self.second_endpoint_to_S[i_edge]\n",
    "                    ) or (self.second_endpoint_to_u[i_edge] and self.first_endpoint_to_S[i_edge])\n",
    "                   ) and (self.edge_label[i_edge]==1):\n",
    "                    outside_edge_cost +=1\n",
    "            \n",
    "            return outside_edge_cost*self.n_edges/self.n_sample_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dynamic-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredAwareUncluster:\n",
    "    '''\n",
    "    This is the class that implements the predecessor-aware non-edge sketh\n",
    "    '''\n",
    "    def __init__(self, vertex_name, n_vertex, pred_set, eps=0.2, delta=0.1):\n",
    "        '''\n",
    "        :param n_vertex: the the number of vertices in the graph\n",
    "        '''\n",
    "        if vertex_name in pred_set:\n",
    "            raise ValueError('The tested vertex cannot be inside the set!')\n",
    "        self.n_vertex = n_vertex\n",
    "        self.n_edges = (int)(n_vertex*(n_vertex-1)/2)\n",
    "        self.vertex_name = vertex_name\n",
    "        self.vertex_degree = 0\n",
    "        self.eps = eps\n",
    "        self.delta = delta\n",
    "        # sample a set of log n vertices\n",
    "        self.n_sample_edges = max((int)(5*np.log(self.n_vertex)), 20)\n",
    "        self.sample_edge_set = []\n",
    "        self.first_endpoint_set = []\n",
    "        self.second_endpoint_set = []\n",
    "        # keep track of the endpoints' connection to u and S\n",
    "        self.first_endpoint_to_u = self.n_sample_edges*[False]\n",
    "        self.first_endpoint_to_S = self.n_sample_edges*[False]\n",
    "        self.second_endpoint_to_u = self.n_sample_edges*[False]\n",
    "        self.second_endpoint_to_S = self.n_sample_edges*[False]\n",
    "        for i_edge in range(self.n_sample_edges):\n",
    "            # to avoid sample the same vertex, try repetitive sampling\n",
    "            while(True):\n",
    "                first_vertex = np.random.choice(self.n_vertex, 1)[0]\n",
    "                second_vertex = np.random.choice(self.n_vertex, 1)[0]\n",
    "                if first_vertex!=second_vertex:\n",
    "                    break\n",
    "            self.sample_edge_set.append((first_vertex, second_vertex))\n",
    "            self.first_endpoint_set.append(first_vertex)\n",
    "            self.second_endpoint_set.append(second_vertex)\n",
    "            if first_vertex == self.vertex_name:\n",
    "                self.first_endpoint_to_u[i_edge] = True\n",
    "            if second_vertex == self.vertex_name:\n",
    "                self.second_endpoint_to_u[i_edge] = True\n",
    "            if first_vertex in pred_set:\n",
    "                self.first_endpoint_to_S[i_edge] = True\n",
    "            if second_vertex in pred_set:\n",
    "                self.second_endpoint_to_S[i_edge] = True\n",
    "        # edge labels\n",
    "        self.edge_label = self.n_sample_edges*[0]\n",
    "        self.pred_set = pred_set\n",
    "        \n",
    "    def read_edge_and_process(self, e, label):\n",
    "        for i_edge in range(self.n_sample_edges):\n",
    "            # if edge is some (x,y), update the label\n",
    "            this_edge_name = self.sample_edge_set[i_edge]\n",
    "            if this_edge_name==e or this_edge_name==(e[1],e[0]):\n",
    "                self.edge_label[i_edge] = label\n",
    "            # if edge connects x (or y) to u, mark it\n",
    "            if (self.first_endpoint_set[i_edge] in e) and (self.vertex_name in e) and (label == 1):\n",
    "                self.first_endpoint_to_u[i_edge] = True\n",
    "            if (self.second_endpoint_set[i_edge] in e) and (self.vertex_name in e) and (label == 1):\n",
    "                self.second_endpoint_to_u[i_edge] = True\n",
    "            # if there is intersection with S, mark it\n",
    "            if (self.first_endpoint_set[i_edge] in e) and list(set(e).\n",
    "                                                               intersection(set(self.pred_set))) and (label == 1):\n",
    "                self.first_endpoint_to_S[i_edge] = True\n",
    "            if (self.second_endpoint_set[i_edge] in e) and list(set(e).intersection(set(self.pred_set))) and (label == 1):\n",
    "                self.second_endpoint_to_S[i_edge] = True\n",
    "        # don't forget to count degree :D\n",
    "        if self.vertex_name in e and label==1:\n",
    "            self.vertex_degree += 1\n",
    "                \n",
    "    def determine_cost(self):\n",
    "        outside_uncluster_cost = 0\n",
    "        if self.vertex_degree<=self.delta*self.n_vertex:\n",
    "            return self.delta*self.n_vertex\n",
    "        for i_edge in range(self.n_sample_edges):\n",
    "            if (not self.first_endpoint_to_S[i_edge]\n",
    "               ) and (not self.second_endpoint_to_S[i_edge]\n",
    "                     ) and self.edge_label[i_edge]==1:\n",
    "                if (self.first_endpoint_to_u[i_edge]) and (not self.second_endpoint_to_S[i_edge]):\n",
    "                    outside_uncluster_cost +=1\n",
    "                if (not self.first_endpoint_to_u[i_edge]) and (self.second_endpoint_to_S[i_edge]):\n",
    "                    outside_uncluster_cost += 1\n",
    "            \n",
    "        return outside_uncluster_cost*self.n_edges/self.n_sample_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fresh-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyMIS:\n",
    "    '''\n",
    "    This class stored all the edges between the sampled vertices and compute the greedy MIS in the end\n",
    "    '''\n",
    "    def __init__(self, ordered_set):\n",
    "        '''\n",
    "        :param ordered_set: an ordered set of vertices\n",
    "        '''\n",
    "        # cast as array if not already\n",
    "        self.num_stored_edge = 0\n",
    "        self.ordered_set = np.array(ordered_set)\n",
    "        self.n_sampled_vertex = self.ordered_set.shape[0]\n",
    "        self.neighbor_vertex_list = []\n",
    "        self.neighbor_vertex_ind_list = []\n",
    "        for i_vertex in range(self.n_sampled_vertex):\n",
    "            self.neighbor_vertex_list.append([self.ordered_set[i_vertex]])\n",
    "            self.neighbor_vertex_ind_list.append([i_vertex])\n",
    "        \n",
    "    def read_edge_and_process(self, e, label):\n",
    "        if (label==1) and (e[0] in self.ordered_set) and (e[1] in self.ordered_set):\n",
    "            vertex_ind_one = np.where(self.ordered_set==e[0])[0][0]\n",
    "            vertex_ind_two = np.where(self.ordered_set==e[1])[0][0]\n",
    "            center_ind = min(vertex_ind_one, vertex_ind_two)\n",
    "            neighbor_ind = max(vertex_ind_one, vertex_ind_two)\n",
    "            self.neighbor_vertex_list[center_ind].append(self.ordered_set[neighbor_ind])\n",
    "            self.neighbor_vertex_ind_list[center_ind].append(neighbor_ind)\n",
    "            self.num_stored_edge += self.num_stored_edge\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def computeMIS(self):\n",
    "        MIS_lists = []\n",
    "        available_inds = np.arange(self.n_sampled_vertex).tolist()\n",
    "        while len(available_inds)>0:\n",
    "            remain_vertices = self.ordered_set[np.array(available_inds)]\n",
    "            current_center_ind = available_inds[0]\n",
    "            current_component = set(self.neighbor_vertex_list[current_center_ind]).intersection(set(remain_vertices))\n",
    "            MIS_lists.append(list(current_component))\n",
    "            available_inds = list(set(available_inds)-set(self.neighbor_vertex_ind_list[current_center_ind]))\n",
    "        \n",
    "        return MIS_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "supreme-indian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 499498/499500 [00:01<00:00, 292398.92it/s]\n"
     ]
    }
   ],
   "source": [
    "sbm_graph_stream.reset_index()\n",
    "ordered_set = np.random.choice(sbm_graph_stream.n_vertex, 10, replace=False)\n",
    "greedy_MIS_extracter = GreedyMIS(ordered_set)\n",
    "for i in tqdm.tqdm(range(sbm_graph_stream.num_edges)):\n",
    "    this_edge, this_edge_label = sbm_graph_stream.read_next_edge()\n",
    "    if this_edge is None:\n",
    "        break\n",
    "    greedy_MIS_extracter.read_edge_and_process(this_edge, this_edge_label)\n",
    "test_MIS_comp = greedy_MIS_extracter.computeMIS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "novel-night",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[873, 547, 606], [402], [720, 132, 29], [708], [645], [151]]\n",
      "[547 402  29 606 645 132 873 151 720 708]\n"
     ]
    }
   ],
   "source": [
    "print(test_MIS_comp)\n",
    "print(ordered_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-board",
   "metadata": {},
   "source": [
    "### In this first version of implementation allow two passes to bring down the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "hawaiian-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_alg_two_pass(graph_stream, eps=0.2, delta=0.1, add_error=False, rescale_spr=False):\n",
    "    n_vertex = graph_stream.n_vertex\n",
    "    n_edges = sbm_graph_stream.num_edges\n",
    "    n_sample_vertex = min(13, int(1/delta)) # cap it at 13 since otherwise the memory explodes\n",
    "    total_edges_store = 0\n",
    "    \n",
    "    # initialize all the tools for process\n",
    "    print('Pre-processing...')\n",
    "    ordered_set = np.random.choice(sbm_graph_stream.n_vertex, n_sample_vertex, replace=False)\n",
    "    # greedy MIS extractor\n",
    "    greedy_MIS_extracter = GreedyMIS(ordered_set)\n",
    "    \n",
    "    print('Processing first pass of the stream...')\n",
    "    # read the stream and process on-the-fly\n",
    "    for i in tqdm.tqdm(range(n_edges)):\n",
    "        this_edge, this_edge_label = sbm_graph_stream.read_next_edge()\n",
    "        if this_edge is None:\n",
    "            break\n",
    "        greedy_MIS_extracter.read_edge_and_process(this_edge, this_edge_label)\n",
    "    total_edges_store = total_edges_store + greedy_MIS_extracter.num_stored_edge\n",
    "    \n",
    "    print('Transition between the passes...')\n",
    "    greedy_MIS_comp = greedy_MIS_extracter.computeMIS()\n",
    "    prev_set = np.array([])\n",
    "    NE_tool_list = []\n",
    "    E_tool_list = []\n",
    "    Unclust_tool_list = []\n",
    "    for i_comp in range(len(greedy_MIS_comp)):\n",
    "        u_vertex = greedy_MIS_comp[i_comp][0]\n",
    "        NE_tool_list.append(PredAwareNE(u_vertex, n_vertex, prev_set))\n",
    "        E_tool_list.append(PredAwareE(u_vertex, n_vertex, prev_set))\n",
    "        Unclust_tool_list.append(PredAwareUncluster(u_vertex, n_vertex, prev_set))\n",
    "        prev_set = np.array(prev_set.tolist()+greedy_MIS_comp[i_comp])\n",
    "        # count the number of vertex pairs used by the tool\n",
    "        total_edges_store += NE_tool_list[i_comp].n_sample_edges\n",
    "        total_edges_store += E_tool_list[i_comp].n_sample_edges\n",
    "        total_edges_store += Unclust_tool_list[i_comp].n_sample_edges\n",
    "      \n",
    "        \n",
    "    # this line is the 'cheating' that we allow a second pass\n",
    "    graph_stream.reset_index()\n",
    "    \n",
    "    print('Processing second pass of the stream...')\n",
    "    # read the stream and process on-the-fly\n",
    "    for i in tqdm.tqdm(range(n_edges)):\n",
    "        this_edge, this_edge_label = sbm_graph_stream.read_next_edge()\n",
    "        if this_edge is None:\n",
    "            break\n",
    "        for i_comp in range(len(greedy_MIS_comp)):\n",
    "            NE_tool_list[i_comp].read_edge_and_process(this_edge, this_edge_label)\n",
    "            E_tool_list[i_comp].read_edge_and_process(this_edge, this_edge_label)\n",
    "            Unclust_tool_list[i_comp].read_edge_and_process(this_edge, this_edge_label)\n",
    "    \n",
    "    # post-processing\n",
    "    print('Post-processing...')\n",
    "    total_cost = 0\n",
    "    for i_comp in range(len(greedy_MIS_comp)):\n",
    "        total_cost = total_cost + NE_tool_list[i_comp].determine_cost()\n",
    "        total_cost = total_cost + E_tool_list[i_comp].determine_cost()\n",
    "        total_cost = total_cost + Unclust_tool_list[i_comp].determine_cost()\n",
    "    \n",
    "    return total_cost, total_edges_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "utility-energy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 42632/499500 [00:00<00:01, 426277.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing...\n",
      "Processing first pass of the stream...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 499498/499500 [00:01<00:00, 475366.89it/s]\n",
      "  0%|          | 641/499500 [00:00<02:35, 3216.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition between the passes...\n",
      "Processing second pass of the stream...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 499498/499500 [02:36<00:00, 3197.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sbm_graph_stream.reset_index()\n",
    "pivot_cost_est, pivot_total_stored_edge = pivot_alg_two_pass(sbm_graph_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "experimental-million",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected SBM cost is  100041\n",
      "The estimated correlation clustering cost is  176294.11764705883\n"
     ]
    }
   ],
   "source": [
    "print('The expected SBM cost is ', sbm_graph_stream.cc_cost)\n",
    "print('The estimated correlation clustering cost is ', pivot_cost_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "corporate-supplement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of edges in the graphs is  499500\n",
      "The number of edges stored by the algorithm is  306\n"
     ]
    }
   ],
   "source": [
    "print('The number of edges in the graphs is ', sbm_graph_stream.num_edges)\n",
    "print('The number of edges stored by the algorithm is ', pivot_total_stored_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-reception",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
