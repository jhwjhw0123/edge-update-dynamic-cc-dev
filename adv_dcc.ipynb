{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159e44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from utils import *\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-parts",
   "metadata": {},
   "source": [
    "## The functions that implements our algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "modern-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sparse_vertex(current_graph, eps=0.2):\n",
    "    # sample log n neighbors for each vertex\n",
    "    current_num_vertex = len(current_graph)\n",
    "    num_sample = max((int)(5*np.log(current_num_vertex)), 20)\n",
    "    sample_dict = {}\n",
    "    for this_vertex in current_graph:\n",
    "        sample_vertex_set = current_graph[this_vertex].getRandom(i=num_sample)\n",
    "        sample_dict[this_vertex] = sample_vertex_set\n",
    "    sparse_vertex_list = []\n",
    "    # test sparsity for each vertex\n",
    "    for this_vertex in current_graph:\n",
    "        num_neighbor_diff = 0\n",
    "        neighbors_this = sample_dict[this_vertex]\n",
    "        for comp_vertex in sample_dict[this_vertex]:\n",
    "            neighbors_comp = sample_dict[comp_vertex]\n",
    "            dif1 = np.setdiff1d(neighbors_this, neighbors_comp)\n",
    "            dif2 = np.setdiff1d(neighbors_comp, neighbors_this)\n",
    "            total_diff = len(np.concatenate((dif1, dif2)))\n",
    "            max_degree_between_two = max(current_graph[this_vertex].degree, \n",
    "                                         current_graph[comp_vertex].degree)\n",
    "            if (total_diff>=eps*num_sample):\n",
    "                num_neighbor_diff = num_neighbor_diff + 1\n",
    "        if num_neighbor_diff >=eps*num_sample:\n",
    "            sparse_vertex_list.append(this_vertex)\n",
    "    \n",
    "    # return the list of sparse vertices\n",
    "    return sparse_vertex_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "amateur-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_dense_decop(current_graph, eps=0.2):\n",
    "    current_num_vertex = len(current_graph)\n",
    "    # check sparse vertices\n",
    "    current_sparse_vertice = test_sparse_vertex(current_graph, eps=eps)\n",
    "    # sample from the dense vertices\n",
    "    dense_subgraph = {vertex: current_graph[vertex] \n",
    "                      for vertex in current_graph if vertex not in current_sparse_vertice}\n",
    "    anchor_vertex_dict = {}\n",
    "    for this_vertex in dense_subgraph.keys():\n",
    "        # rejection sampling\n",
    "        dense_sample_prob = max((5*np.log(current_num_vertex))/dense_subgraph[this_vertex].degree, 0.05)\n",
    "        if dense_sample_prob>=np.random.uniform(low=0.0, high=1.0):\n",
    "            anchor_vertex_dict[this_vertex] = dense_subgraph[this_vertex]\n",
    "    # recursively form almost-cliques\n",
    "    num_sample = max((int)(5*np.log(current_num_vertex)), 20)\n",
    "    AC_dict = {}\n",
    "    # maintain a list of covered vertices\n",
    "    covered_AC_vertex = []\n",
    "    for this_anchor_vertex in anchor_vertex_dict.keys():\n",
    "        if this_anchor_vertex in covered_AC_vertex:\n",
    "            continue\n",
    "        AC_dict[this_anchor_vertex] = []\n",
    "        covered_AC_vertex.append(this_anchor_vertex)\n",
    "        anchor_neighbor_samples = anchor_vertex_dict[this_anchor_vertex].getRandom(i=num_sample)\n",
    "        for candidate_vertex in anchor_vertex_dict[this_anchor_vertex]:\n",
    "            if (candidate_vertex in current_sparse_vertice) or (candidate_vertex in covered_AC_vertex):\n",
    "                continue\n",
    "            cand_neighbor_samples = dense_subgraph[candidate_vertex].getRandom(i=num_sample)\n",
    "            # test whether their symmetric difference is large enough\n",
    "            dif1 = np.setdiff1d(anchor_neighbor_samples, cand_neighbor_samples)\n",
    "            dif2 = np.setdiff1d(cand_neighbor_samples, anchor_neighbor_samples)\n",
    "            total_diff = len(np.concatenate((dif1, dif2)))\n",
    "            max_degree_between_two = max(dense_subgraph[this_anchor_vertex].degree, \n",
    "                                         dense_subgraph[candidate_vertex].degree)\n",
    "            if (total_diff<=2*eps*num_sample):\n",
    "                AC_dict[this_anchor_vertex].append(candidate_vertex)\n",
    "                covered_AC_vertex.append(candidate_vertex)\n",
    "            # this line is for debugging purpose -- remove later\n",
    "            else:\n",
    "                # it appears that this line has never been entered...\n",
    "                print('something interesting is happening!')\n",
    "   \n",
    "    dense_vertex_list = [v for v in current_graph if v not in current_sparse_vertice]\n",
    "    \n",
    "    return current_sparse_vertice, AC_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-budapest",
   "metadata": {},
   "source": [
    "## Read the edges and maintain clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "97b030cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adjacency_list, edge_list = create_graph_from_csv(\"../data/email-Eu-core.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "2252f748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO\\n\\nSee if functions are doable\\n\\n'"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TODO\n",
    "\n",
    "See if functions are doable\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "18b1a0e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "[ 276  432  449  501  522  553  574  599  628  629  632  634  639  645\n",
      "  648  650  653  659  664  670  677  680  689  693  696  704  712  736\n",
      "  746  757  763  771  780  786  788  793  797  799  801  830  848  855\n",
      "  858  862  874  884  889  893  912  964  969  973  984  991  993  995\n",
      " 1002]\n",
      "===============================\n",
      "[]\n",
      "******************************\n",
      "The number of almost-cliques is  338\n"
     ]
    }
   ],
   "source": [
    "no_edges = len(edge_list)  # No. of edges\n",
    "\n",
    "prob_del = 0.2      # Probability to delete edge\n",
    "eps_param = 0.1\n",
    "\n",
    "current_graph = {}\n",
    "current_edge_list = []\n",
    "\n",
    "available_edge_list = np.random.permutation(edge_list).tolist()\n",
    "\n",
    "stream_length = 2*no_edges\n",
    "\n",
    "track_update_num = {}\n",
    "track_update_benckmark = {}\n",
    "\n",
    "for i in range(stream_length):\n",
    "    # Insertion\n",
    "    if available_edge_list: #\n",
    "        current_edge_list.append(available_edge_list[i])\n",
    "        u = available_edge_list[i][0]\n",
    "        v = available_edge_list[i][1]\n",
    "        if u not in current_graph.keys():\n",
    "            current_graph[u] = OptList()\n",
    "        current_graph[u].insert(v)\n",
    "        if v not in current_graph.keys():\n",
    "            current_graph[v] = OptList()\n",
    "        current_graph[v].insert(u)\n",
    "        available_edge_list.pop(0)\n",
    "        \n",
    "        # keep track of the benchmark for the updates\n",
    "        if u not in track_update_benckmark:\n",
    "            track_update_benckmark[u] = current_graph[u].degree\n",
    "        if v not in track_update_benckmark:\n",
    "            track_update_benckmark[v] = current_graph[v].degree\n",
    "        # update the tracking of the updates on u and v\n",
    "        if u not in track_update_num:\n",
    "            track_update_num[u] = 1\n",
    "        else:\n",
    "            track_update_num[u] = track_update_num[u] + 1\n",
    "            \n",
    "        if v not in track_update_num:\n",
    "            track_update_num[v] = 1\n",
    "        else:\n",
    "            track_update_num[v] = track_update_num[v] + 1\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Code for SDD and PIVOT goes here\n",
    "        '''\n",
    "        if (track_update_num[u]>max(100, eps_param*track_update_benckmark[u])):\n",
    "            # tests\n",
    "            current_sparse_vertex_list, almost_cliques = sparse_dense_decop(current_graph)\n",
    "            # clear the number of updates\n",
    "            track_update_num[u] = 0\n",
    "            track_update_benckmark = current_graph[u].degree\n",
    "            all_vertex_list = [v for v in current_graph]\n",
    "\n",
    "            AC_vertex_list = []\n",
    "            for anchor_ver in almost_cliques.keys():\n",
    "                AC_vertex_list.append(anchor_ver)\n",
    "                for ac_ver in almost_cliques[anchor_ver]:\n",
    "                    AC_vertex_list.append(ac_ver)\n",
    "            AC_vertex_list = list(set(AC_vertex_list))\n",
    "            recovered_vertex = np.concatenate((AC_vertex_list, current_sparse_vertex_list))\n",
    "            print('===============================')\n",
    "            print(np.setdiff1d(all_vertex_list,recovered_vertex))\n",
    "            print('******************************')\n",
    "            print('The number of almost-cliques is ', len(almost_cliques))\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        # We have run out of edges to insert\n",
    "        edge_to_delete = np.random.choice(current_edge_list)\n",
    "        \n",
    "        u = edge_to_delete[0]\n",
    "        v = edge_to_delete[1]\n",
    "        current_graph[u].remove(v)\n",
    "        current_graph[v].remove(u)\n",
    "        \n",
    "        available_edge_list.extend(edge_to_delete)\n",
    "        current_edge_list.remove(edge_to_delete)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "#     if np.random.binomial(1,prob_del):\n",
    "#         # Deletion\n",
    "#         print(current_edge_list)\n",
    "#         edge_to_delete = np.random.choice(current_edge_list)\n",
    "        \n",
    "#         u = edge_to_delete[0]\n",
    "#         v = edge_to_delete[1]\n",
    "#         current_graph[u].remove(v)\n",
    "#         current_graph[v].remove(u)\n",
    "        \n",
    "#         available_edge_list.extend(edge_to_delete)\n",
    "#         current_edge_list.remove(edge_to_delete)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ddce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
